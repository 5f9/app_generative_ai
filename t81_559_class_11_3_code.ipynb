{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxu1Gfhx1pHg"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffheaton/app_generative_ai/blob/main/t81_559_class_11_3_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbNbAV281pHh"
      },
      "source": [
        "# T81-559: Applications of Generative Artificial Intelligence\n",
        "**Module 11: Finetuning**\n",
        "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
        "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwnvSYEQ1pHi"
      },
      "source": [
        "# Module 11 Material\n",
        "\n",
        "Module 11: Finetuning\n",
        "\n",
        "* Part 11.1: Understanding Finetuning [[Video]]() [[Notebook]](t81_559_class_11_1_finetune.ipynb)\n",
        "* Part 11.2: Finetuning from the Dashboard [[Video]]() [[Notebook]](t81_559_class_11_2_dashboard.ipynb)\n",
        "* **Part 11.3: Finetuning from Code** [[Video]]() [[Notebook]](t81_559_class_11_3_code.ipynb)\n",
        "* Part 11.4: Evaluating your Model [[Video]]() [[Notebook]](t81_559_class_11_4_eval.ipynb)\n",
        "* Part 11.5: Finetuning for Text to Image [[Video]]() [[Notebook]](t81_559_class_11_5_image.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLFov09h18yC"
      },
      "source": [
        "# Google CoLab Instructions\n",
        "\n",
        "The following code ensures that Google CoLab is running and maps Google Drive if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWGARRT92DrA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    from google.colab import drive, userdata\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False\n",
        "\n",
        "# OpenAI Secrets\n",
        "if COLAB:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Install needed libraries in CoLab\n",
        "if COLAB:\n",
        "    !pip install langchain openai streamlit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2MPPX0c1pHi"
      },
      "source": [
        "# Part 11.3: Finetuning from Code\n",
        "\n",
        "Just like the last part we will utilize the following training data.\n",
        "\n",
        "* [sarcastic.jsonl](https://data.heatonresearch.com/data/t81-559/finetune/sarcastic.jsonl)\n",
        "* [sarcastic_val.jsonl](https://data.heatonresearch.com/data/t81-559/finetune/sarcastic_val.jsonl)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "!wget https://data.heatonresearch.com/data/t81-559/finetune/sarcastic.jsonl\n",
        "!wget https://data.heatonresearch.com/data/t81-559/finetune/sarcastic_val.jsonl\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "obj = client.files.create(\n",
        "  file=open(\"sarcastic.jsonl\", \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")"
      ],
      "metadata": {
        "id": "OawqUP3Jr85z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obj.id"
      ],
      "metadata": {
        "id": "7TZeEIbtyXxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "status"
      ],
      "metadata": {
        "id": "kQEFmRLzHCQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run and Monitor Finetuning"
      ],
      "metadata": {
        "id": "slJEgf6XiFDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from openai import OpenAI\n",
        "\n",
        "# Start the fine-tuning job\n",
        "train = client.fine_tuning.jobs.create(\n",
        "    training_file=obj.id,\n",
        "    model=\"gpt-4o-mini-2024-07-18\"\n",
        ")\n",
        "\n",
        "done = False\n",
        "\n",
        "# Initialize a set to store processed event IDs\n",
        "processed_event_ids = set()\n",
        "\n",
        "while not done:\n",
        "    # Retrieve the latest status of the fine-tuning job\n",
        "    status = client.fine_tuning.jobs.retrieve(train.id)\n",
        "    print(f\"Job status: {status.status}\")\n",
        "\n",
        "    # Fetch all events related to the fine-tuning job\n",
        "    events = client.fine_tuning.jobs.list_events(fine_tuning_job_id=train.id)\n",
        "\n",
        "    # Collect new events that haven't been processed yet\n",
        "    new_events = []\n",
        "    for event in events:\n",
        "        if event.id not in processed_event_ids:\n",
        "            new_events.append(event)\n",
        "            processed_event_ids.add(event.id)\n",
        "\n",
        "    # Sort the new events in chronological order\n",
        "    new_events.sort(key=lambda e: e.created_at)\n",
        "\n",
        "    # Display the new events in order\n",
        "    for event in new_events:\n",
        "        print(f\"{event.created_at}: {event.message}\")\n",
        "\n",
        "    if status.status == \"succeeded\":\n",
        "        done = True\n",
        "        print(\"Done!\")\n",
        "    elif status.status == \"failed\":\n",
        "        done = True\n",
        "        print(\"Failed!\")\n",
        "    else:\n",
        "        print(\"Waiting for updates...\")\n",
        "        time.sleep(20)  # Sleep for 20 seconds\n"
      ],
      "metadata": {
        "id": "MSgK0cLbfDZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = status.fine_tuned_model\n",
        "print(f\"Trained model id: {model_id}\")"
      ],
      "metadata": {
        "id": "aRVAzHzYjT8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test the Finetuned Model"
      ],
      "metadata": {
        "id": "xqdT0CyTiq2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=model_id,\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What is the capital of the USA?\"}\n",
        "  ]\n",
        ")\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "id": "l5Eeuf3JiT6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Delete Old Models"
      ],
      "metadata": {
        "id": "ukvYwN20ilos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#client.models.delete(\"ft:gpt-4o-mini-2024-07-18:personal:sarcastic:A9yCtR0b\")"
      ],
      "metadata": {
        "id": "gPTpmdYbiOxp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}